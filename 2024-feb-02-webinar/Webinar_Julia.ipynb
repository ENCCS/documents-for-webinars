{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1f2172-9c8d-47d3-b332-52bcefb2763f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Short tour of Julia for GPU programming and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10726e68-972a-47ac-8da9-24c9607f18ff",
   "metadata": {},
   "source": [
    "[Julia](https://julialang.org/) is a scientific programming language that is free and open source for downloads, documentation, learning resources etc. Bridging high-level interpreted and low-level compiled languages, it offers high performance (comparable to C and Fortran) without sacrificing simplicity and programming productivity (like in Python or R).\n",
    "\n",
    "Julia has a rich ecosystem of libraries aimed towards scientific computing and a powerful built-in package manager to install and manage their dependencies. Julia is also gaining ground in HPC as it supports both multithreaded and distributed-memory parallelisation, as well as GPU computing.\n",
    "\n",
    "ENCCS provides learning materials for Julia programming:\n",
    "- [Introduction to programming in Julia](https://enccs.github.io/julia-intro/)\n",
    "- [Julia for High-Performance Data Analytics](https://enccs.github.io/julia-for-hpda/)\n",
    "- [Julia for High-Performance Scientific Computing](https://enccs.github.io/julia-for-hpc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df4aa7-8f24-417d-9aae-e43e740112ed",
   "metadata": {},
   "source": [
    "## Julia was created to solve the two-language problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e55a7d-138c-46bc-bd02-4753a74416b5",
   "metadata": {},
   "source": [
    "To run code in any programming language, some sort of translation into machine instructions needs to take place, but how this translation takes place differs between programming languages:\n",
    "- Interpreted languages like Python and R translate instructions line by line.\n",
    "- Compiled languages like C/C++ and Fortran are translated by a compiler prior to program execution.\n",
    "\n",
    "The benefits of interpreted languages are that they are easier to read and write because less information on aspects like types and array sizes needs to be provided. Programmer productivity is thus higher in interpreted languages, but compiled languages can perform faster by orders of magnitude because the compiler can perform optimizations during the translation to assembly. This is also known as the *two-language problem*.\n",
    "\n",
    "In many ways Julia looks like an interpreted language, and mostly behaves like one. But before each function is executed, Julia’s LLVM compiler will compile it `“just in time” (JIT)`. More on that later. Thus you get the flexibility of an interpreted language and the execution speed of the compiled language at the cost of waiting a bit longer for the first execution of any function.\n",
    "\n",
    "Julia has been designed to be both fast and dynamic. In the words of its developers: \n",
    "\n",
    "> We want a language that’s open source, with a liberal license. We want the speed of C with the dynamism of Ruby. We want a language that’s homoiconic, with true macros like Lisp, but with obvious, familiar mathematical notation like Matlab. We want something as usable for general programming as Python, as easy for statistics as R, as natural for string processing as Perl, as powerful for linear algebra as Matlab, as good at gluing programs together as the shell. Something that is dirt simple to learn, yet keeps the most serious hackers happy. We want it interactive and we want it compiled. (Did we mention it should be as fast as C?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb4c5a-6717-41f0-9ddc-3d277376e41c",
   "metadata": {},
   "source": [
    "## Julia Micro-Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018da37-1ee9-4b58-a2d1-10819e46164f",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://julialang.org/assets/images/benchmarks.svg\", width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e55c65-a751-435a-8dfe-6db4ef02e6bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Basic syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63433095-2950-4336-861d-b6d01c8ded61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464d91f2-400c-48aa-85c8-2e1e7e0db95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14 --- Float64\n",
      "10 --- Int64\n",
      "true --- Bool\n",
      "3 + 4im --- Complex{Int64}\n",
      "hello, Julia --- String\n",
      "(Float64, AbstractFloat, Real, Number, Any) --- Type[]"
     ]
    }
   ],
   "source": [
    "A = 3.14\n",
    "println(A, \" --- \", typeof(A))\n",
    "\n",
    "B = 10\n",
    "println(B, \" --- \", typeof(B))\n",
    "\n",
    "C = true\n",
    "println(C, \" --- \", typeof(C))\n",
    "\n",
    "D = 3+4im\n",
    "println(D, \" --- \", typeof(D))\n",
    "\n",
    "E = \"Hello, Julia\"\n",
    "println(E, \" --- \", typeof(E))\n",
    "\n",
    "# supertypes and subtypes\n",
    "print(supertypes(Float64), \" --- \", subtypes(Int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b407026-ee91-4d08-8220-9d7746bd6646",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vectors and Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7249f064-ade5-4baa-9d95-85396864b2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       "  0\n",
       "  6\n",
       " 24\n",
       " 60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1 = [1, 2, 3, 4] # 4-element Vector{Int64}\n",
    "a2 = [i^3 for i in [1,2,3,4]] # Array comprehension\n",
    "\n",
    "m1 = [[1,2]  [4,5]  [7,8]] # 2×3 Matrix{Int64}\n",
    "m2 = zeros(4,4,4,4) # Zero 4×4×4×4 Array{Float64, 4}\n",
    "\n",
    "# broadcasting\n",
    "b1 = a1.^2\n",
    "b2 = a2 .- a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745477b4-6867-454a-9b0f-00f08db72676",
   "metadata": {},
   "source": [
    "## Loops and Conditionals\n",
    "\n",
    "`for` loops iterate over iterables, including types like `Range`, `Array`, `Set` and `Dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aa81c99-5f70-473a-aff4-6a38c617c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1\n",
      "i = 2\n",
      "i = 3\n",
      "i = 4\n",
      "i = 5\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2,3,4,5]\n",
    "    println(\"i = $i\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbac6471-56af-435a-9844-50841c5f5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1, A[i] = 1\n",
      "i = 2, A[i] = 3\n",
      "i = 3, A[i] = 2\n",
      "i = 4, A[i] = 4\n"
     ]
    }
   ],
   "source": [
    "A = [1 2; 3 4]\n",
    "# visit each index of A efficiently\n",
    "for i in eachindex(A)\n",
    "    println(\"i = $i, A[i] = $(A[i])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9576994-9b22-40fd-bb06-5b3865ebfa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B is 2\n",
      "A is 1\n",
      "C is 3\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in Dict(\"A\" => 1, \"B\" => 2, \"C\" => 3)\n",
    "    println(\"$k is $v\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2ff15-4aef-4a28-9428-78290b61e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 6\n",
    "if x > 5\n",
    "    println(\"x > 5\")\n",
    "elseif x < 5    # optional elseif\n",
    "    println(\"x < 5\")\n",
    "else            # optional else\n",
    "    println(\"x = 5\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb0c61-90ff-4d7d-84bf-86e8c78d996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "while n < 10\n",
    "    n += 1\n",
    "    println(n)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45321a3-314f-4a93-ab3e-40d2a64eeb4a",
   "metadata": {},
   "source": [
    "## Working with files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8185f9db-c86d-44d5-8124-14ef11e84552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"another line\"]\n"
     ]
    }
   ],
   "source": [
    "open(\"myfile.txt\", \"w\") do f\n",
    "    write(f, \"a line\")\n",
    "end\n",
    "\n",
    "open(\"myfile.txt\") do f\n",
    "    # read from file\n",
    "    lines = readlines(f)\n",
    "    println(lines)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2883a-6130-4ab5-9e4f-d8891f20b4b6",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39de13fe-7909-4eba-8174-ba8905b21a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function f(x,y)\n",
    "    x + y   # can also use \"return\" keyword\n",
    "end\n",
    "\n",
    "f(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b973d-e10b-4ca6-a99f-882cabacb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keyword arguments can be added after `;`\n",
    "\n",
    "function greet_dog(; greeting = \"Hi\", dog_name = \"Fido\")  # note the ;\n",
    "    println(\"$greeting $dog_name\")\n",
    "end\n",
    "\n",
    "greet_dog(dog_name = \"Coco\", greeting = \"Go fetch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592297f-ba61-4b8e-8251-a487d6742a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional arguments\n",
    "\n",
    "function date(y, m=2, d=2)\n",
    "    month = lpad(m, 2, \"0\")  # lpad pads from the left\n",
    "    day = lpad(d, 2, \"0\")\n",
    "    println(\"$y-$month-$day\")\n",
    "end\n",
    "\n",
    "date(2024)\n",
    "date(2024, 3)\n",
    "date(2024, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696df91-37f6-4579-982b-6916117ea338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument types can be specified explicitly\n",
    "function f(x::Float64, y::Float64)\n",
    "    return x*y\n",
    "end\n",
    "\n",
    "# return types can also be specified\n",
    "function g(x, y)::Int8\n",
    "    return x * y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484ee50-ed66-429f-a91c-3d3dab7014ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Special features of Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26faf6-5f4d-4dfd-8694-3bfd48b03910",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hierarchy Types\n",
    "\n",
    "Julia is a dynamically typed language and does not require users to explicitly declare types because types are inferred and used at runtime. The sophisticated type system helps Julia to generate efficient code.\n",
    "\n",
    "As types play a fundamental role in Julia’s design, it’s important to have a mental model of Julia’s type system. There are two basic kinds of types in Julia:\n",
    "- Abstract types which define the kind of a thing, that is, represent sets of related types.\n",
    "- Concrete types which describe data structures, that is, concrete implementations that can be used for variables.\n",
    "\n",
    "Furthermore, a **primitive type** consists of plain bits such as an integer, character or floating point number. A **parametric type** represents a set of types. Types in Julia form a “type tree”, in which the leaves are concrete types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8eac55-7762-4674-af72-0e9799cd96f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Julia-number-type-hierarchy.svg/1920px-Julia-number-type-hierarchy.svg.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e43ace-90e1-4b63-b005-477a81ea4da6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76acdc72-fd2b-441e-b474-303d3540c167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sumsquare (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function sumsquare(x, y)\n",
    "    return x^2 + y^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db8e14-66d9-45df-994a-187c47fa04cb",
   "metadata": {},
   "source": [
    "Each function can have multiple methods. A method is a function defined for specific arguments types.\n",
    "Here we define methods using short form syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23aebcb5-71df-4e60-811a-a111c881af9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sumsquare (generic function with 4 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sumsquare(x::Float64, y::Float64) = x^2 + y^2\n",
    "sumsquare(x::Int64, y::Int64) = x^2 + y^2\n",
    "sumsquare(x::Complex{Float64}, y::Complex{Float64}) = x^2 + y^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949b98a-0ea1-423b-a722-e9a8d8777917",
   "metadata": {},
   "source": [
    "Julia’s type system also enables `multiple dispatch`, that is, choosing the most specific method of a function based on the argument types. \n",
    "\n",
    "`Multiple dispatch` sets the language apart from most other languages and makes it composable and fast when combined with just-in-time (JIT) compilation using the LLVM compiler toolchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13975166-0ddc-46ff-bfd7-20fd0cbd6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing arguments with all kinds of types to this function\n",
    "\n",
    "# Int64\n",
    "println(sumsquare(2, 3))\n",
    "\n",
    "# Float64\n",
    "println(sumsquare(2.72, 3.83))\n",
    "    \n",
    "# Complex{Float64}\n",
    "println(sumsquare(1.2+2.3im, 2.1-1.5im))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ff5c7-5484-4b73-9d5c-c62a5976466f",
   "metadata": {},
   "source": [
    "We can also create a composite type (a struct), and create a new method for that type. The `Point` composite type below is furthermore *parametric*, where we restrict the type T to be a subtype of `Real`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a493217-354b-404e-b656-f4b5ebb400e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Point{T<:Real}\n",
    "    x::T\n",
    "    y::T\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29f603-ba52-46a8-aa61-3404d8ddf000",
   "metadata": {},
   "source": [
    "We can now create two variables of type `Point`, and define a method for `sumsquare` which accepts this type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e91b7e-6ea8-445b-a8dc-7801fc64a93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point{Float64}(5.0, 13.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function sumsquare(p1::Point, p2::Point)\n",
    "   return Point(p1.x^2 + p2.x^2, p1.y^2 + p2.y^2)\n",
    "end\n",
    "\n",
    "p1, p2 = Point(1.0, 2.0), Point(2.0, 3.0)\n",
    "sumsquare(p1, p2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e96d1b-8c61-4f24-ac16-c5c415a6d944",
   "metadata": {},
   "source": [
    "## Code generation\n",
    "\n",
    "Julia was designed from the beginning for HPC and this is accomplished by compiling Julia programs to efficient native code for multiple platforms via the `LLVM` compiler toolchain and `JIT` compilation. The Julia runtime code generator produces an LLVM **Intermediate Representation** (IR) which the LLMV compiler then converts to machine code using sophisticated optimization technology\n",
    "- Interpreted languages rely on a runtime which directly executes the source code.\n",
    "- Compiled languages rely on ahead-of-time compilation where source code is converted to an executable before execution.\n",
    "- JIT compilation is when code is compiled to machine code at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1af069-5ccf-499c-99cd-848041eb56d4",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://enccs.github.io/julia-intro/_images/julia-code-generation.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f704bbb-d121-49eb-b6d4-f32044a0ec9b",
   "metadata": {},
   "source": [
    "To see the various forms of lowered code that is generated by the JIT compiler we can use several macros. Inspecting the lowered form for functions requires selection of the specific method to display, because generic functions may have many methods with different type signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4f50a07-3688-43f4-a15b-5d8c3ed50769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr\n",
      "  head: Symbol call\n",
      "  args: Array{Any}((3,))\n",
      "    1: Symbol sumsquare\n",
      "    2: Int64 1\n",
      "    3: Int64 2\n",
      "Expr\n",
      "  head: Symbol call\n",
      "  args: Array{Any}((3,))\n",
      "    1: Symbol sumsquare\n",
      "    2: Symbol p1\n",
      "    3: Symbol p2\n",
      "MethodInstance for sumsquare(::Float64, ::Float64)\n",
      "  from sumsquare(\u001b[90mx\u001b[39m::\u001b[1mFloat64\u001b[22m, \u001b[90my\u001b[39m::\u001b[1mFloat64\u001b[22m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90m~/repos/lessons/webinar_documents/2024-feb-02-webinar/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X42sdnNjb2RlLXJlbW90ZQ==.jl:1\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(sumsquare)\u001b[39m\n",
      "  x\u001b[36m::Float64\u001b[39m\n",
      "  y\u001b[36m::Float64\u001b[39m\n",
      "Body\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1 = Main.:^\u001b[36m::Core.Const(^)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %2 = Core.apply_type(Base.Val, 2)\u001b[36m::Core.Const(Val{2})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %3 = (%2)()\u001b[36m::Core.Const(Val{2}())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %4 = Base.literal_pow(%1, x, %3)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %5 = Main.:^\u001b[36m::Core.Const(^)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %6 = Core.apply_type(Base.Val, 2)\u001b[36m::Core.Const(Val{2})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %7 = (%6)()\u001b[36m::Core.Const(Val{2}())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %8 = Base.literal_pow(%5, y, %7)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %9 = (%4 + %8)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %9\n",
      "\n",
      "MethodInstance for sumsquare(::Point{Float64}, ::Point{Float64})\n",
      "  from sumsquare(\u001b[90mp1\u001b[39m::\u001b[1mPoint\u001b[22m, \u001b[90mp2\u001b[39m::\u001b[1mPoint\u001b[22m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90m~/repos/lessons/webinar_documents/2024-feb-02-webinar/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X51sdnNjb2RlLXJlbW90ZQ==.jl:1\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(sumsquare)\u001b[39m\n",
      "  p1\u001b[36m::Point{Float64}\u001b[39m\n",
      "  p2\u001b[36m::Point{Float64}\u001b[39m\n",
      "Body\u001b[36m::Point{Float64}\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1  = Main.:^\u001b[36m::Core.Const(^)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %2  = Base.getproperty(p1, :x)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %3  = Core.apply_type(Base.Val, 2)\u001b[36m::Core.Const(Val{2})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %4  = (%3)()\u001b[36m::Core.Const(Val{2}())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %5  = Base.literal_pow(%1, %2, %4)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %6  = Main.:^\u001b[36m::Core.Const(^)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %7  = Base.getproperty(p2, :x)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %8  = Core.apply_type(Base.Val, 2)\u001b[36m::Core.Const(Val{2})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %9  = (%8)()\u001b[36m::Core.Const(Val{2}())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %10 = Base.literal_pow(%6, %7, %9)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %11 = (%5 + %10)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %12 = Main.:^\u001b[36m::Core.Const(^)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %13 = Base.getproperty(p1, :y)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %14 = Core.apply_type(Base.Val, 2)\u001b[36m::Core.Const(Val{2})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %15 = (%14)()\u001b[36m::Core.Const(Val{2}())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %16 = Base.literal_pow(%12, %13, %15)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %17 = Main.:^\u001b[36m::Core.Const(^)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %18 = Base.getproperty(p2, :y)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %19 = Core.apply_type(Base.Val, 2)\u001b[36m::Core.Const(Val{2})\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %20 = (%19)()\u001b[36m::Core.Const(Val{2}())\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %21 = Base.literal_pow(%17, %18, %20)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %22 = (%16 + %21)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %23 = Main.Point(%11, %22)\u001b[36m::Point{Float64}\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       return %23\n",
      "\n",
      "\u001b[90m;  @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X42sdnNjb2RlLXJlbW90ZQ==.jl:2 within `sumsquare`\u001b[39m\n",
      "\u001b[95mdefine\u001b[39m \u001b[36mi64\u001b[39m \u001b[93m@julia_sumsquare_2497\u001b[39m\u001b[33m(\u001b[39m\u001b[36mi64\u001b[39m \u001b[95msignext\u001b[39m \u001b[0m%0\u001b[0m, \u001b[36mi64\u001b[39m \u001b[95msignext\u001b[39m \u001b[0m%1\u001b[33m)\u001b[39m \u001b[0m#0 \u001b[33m{\u001b[39m\n",
      "\u001b[91mtop:\u001b[39m\n",
      "\u001b[90m; ┌ @ intfuncs.jl:332 within `literal_pow`\u001b[39m\n",
      "\u001b[90m; │┌ @ int.jl:88 within `*`\u001b[39m\n",
      "    \u001b[0m%2 \u001b[0m= \u001b[96m\u001b[1mmul\u001b[22m\u001b[39m \u001b[36mi64\u001b[39m \u001b[0m%0\u001b[0m, \u001b[0m%0\n",
      "    \u001b[0m%3 \u001b[0m= \u001b[96m\u001b[1mmul\u001b[22m\u001b[39m \u001b[36mi64\u001b[39m \u001b[0m%1\u001b[0m, \u001b[0m%1\n",
      "\u001b[90m; └└\u001b[39m\n",
      "\u001b[90m; ┌ @ int.jl:87 within `+`\u001b[39m\n",
      "   \u001b[0m%4 \u001b[0m= \u001b[96m\u001b[1madd\u001b[22m\u001b[39m \u001b[36mi64\u001b[39m \u001b[0m%3\u001b[0m, \u001b[0m%2\n",
      "   \u001b[96m\u001b[1mret\u001b[22m\u001b[39m \u001b[36mi64\u001b[39m \u001b[0m%4\n",
      "\u001b[90m; └\u001b[39m\n",
      "\u001b[33m}\u001b[39m\n",
      "\u001b[90m;  @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X42sdnNjb2RlLXJlbW90ZQ==.jl:1 within `sumsquare`\u001b[39m\n",
      "\u001b[95mdefine\u001b[39m \u001b[36mdouble\u001b[39m \u001b[93m@julia_sumsquare_2518\u001b[39m\u001b[33m(\u001b[39m\u001b[36mdouble\u001b[39m \u001b[0m%0\u001b[0m, \u001b[36mdouble\u001b[39m \u001b[0m%1\u001b[33m)\u001b[39m \u001b[0m#0 \u001b[33m{\u001b[39m\n",
      "\u001b[91mtop:\u001b[39m\n",
      "\u001b[90m; ┌ @ intfuncs.jl:332 within `literal_pow`\u001b[39m\n",
      "\u001b[90m; │┌ @ float.jl:411 within `*`\u001b[39m\n",
      "    \u001b[0m%2 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%0\u001b[0m, \u001b[0m%0\n",
      "    \u001b[0m%3 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%1\u001b[0m, \u001b[0m%1\n",
      "\u001b[90m; └└\u001b[39m\n",
      "\u001b[90m; ┌ @ float.jl:409 within `+`\u001b[39m\n",
      "   \u001b[0m%4 \u001b[0m= \u001b[96m\u001b[1mfadd\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%2\u001b[0m, \u001b[0m%3\n",
      "   \u001b[96m\u001b[1mret\u001b[22m\u001b[39m \u001b[36mdouble\u001b[39m \u001b[0m%4\n",
      "\u001b[90m; └\u001b[39m\n",
      "\u001b[33m}\u001b[39m\n",
      "\u001b[90m;  @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X51sdnNjb2RlLXJlbW90ZQ==.jl:1 within `sumsquare`\u001b[39m\n",
      "\u001b[95mdefine\u001b[39m \u001b[36mvoid\u001b[39m \u001b[93m@julia_sumsquare_2520\u001b[39m\u001b[33m(\u001b[39m\u001b[33m[\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m]\u001b[39m\u001b[0m* \u001b[95mnoalias\u001b[39m \u001b[95mnocapture\u001b[39m \u001b[95mnoundef\u001b[39m \u001b[95mnonnull\u001b[39m \u001b[95msret\u001b[39m\u001b[33m(\u001b[39m\u001b[33m[\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m]\u001b[39m\u001b[33m)\u001b[39m \u001b[95malign\u001b[39m \u001b[33m8\u001b[39m \u001b[95mdereferenceable\u001b[39m\u001b[33m(\u001b[39m\u001b[33m16\u001b[39m\u001b[33m)\u001b[39m \u001b[0m%0\u001b[0m, \u001b[33m[\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m]\u001b[39m\u001b[0m* \u001b[95mnocapture\u001b[39m \u001b[95mnoundef\u001b[39m \u001b[95mnonnull\u001b[39m \u001b[95mreadonly\u001b[39m \u001b[95malign\u001b[39m \u001b[33m8\u001b[39m \u001b[95mdereferenceable\u001b[39m\u001b[33m(\u001b[39m\u001b[33m16\u001b[39m\u001b[33m)\u001b[39m \u001b[0m%1\u001b[0m, \u001b[33m[\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m]\u001b[39m\u001b[0m* \u001b[95mnocapture\u001b[39m \u001b[95mnoundef\u001b[39m \u001b[95mnonnull\u001b[39m \u001b[95mreadonly\u001b[39m \u001b[95malign\u001b[39m \u001b[33m8\u001b[39m \u001b[95mdereferenceable\u001b[39m\u001b[33m(\u001b[39m\u001b[33m16\u001b[39m\u001b[33m)\u001b[39m \u001b[0m%2\u001b[33m)\u001b[39m \u001b[0m#0 \u001b[33m{\u001b[39m\n",
      "\u001b[91mtop:\u001b[39m\n",
      "\u001b[90m;  @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X51sdnNjb2RlLXJlbW90ZQ==.jl:2 within `sumsquare`\u001b[39m\n",
      "\u001b[90m; ┌ @ intfuncs.jl:332 within `literal_pow`\u001b[39m\n",
      "\u001b[90m; │┌ @ float.jl:411 within `*`\u001b[39m\n",
      "    \u001b[0m%3 \u001b[0m= \u001b[96m\u001b[1mbitcast\u001b[22m\u001b[39m \u001b[33m[\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m]\u001b[39m\u001b[0m* \u001b[0m%1 \u001b[95mto\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m*\n",
      "    \u001b[0m%4 \u001b[0m= \u001b[96m\u001b[1mload\u001b[22m\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m, \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m* \u001b[0m%3\u001b[0m, \u001b[95malign\u001b[39m \u001b[33m8\u001b[39m\n",
      "    \u001b[0m%5 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m \u001b[0m%4\u001b[0m, \u001b[0m%4\n",
      "    \u001b[0m%6 \u001b[0m= \u001b[96m\u001b[1mbitcast\u001b[22m\u001b[39m \u001b[33m[\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m]\u001b[39m\u001b[0m* \u001b[0m%2 \u001b[95mto\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m*\n",
      "    \u001b[0m%7 \u001b[0m= \u001b[96m\u001b[1mload\u001b[22m\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m, \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m* \u001b[0m%6\u001b[0m, \u001b[95malign\u001b[39m \u001b[33m8\u001b[39m\n",
      "    \u001b[0m%8 \u001b[0m= \u001b[96m\u001b[1mfmul\u001b[22m\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m \u001b[0m%7\u001b[0m, \u001b[0m%7\n",
      "\u001b[90m; └└\u001b[39m\n",
      "\u001b[90m; ┌ @ float.jl:409 within `+`\u001b[39m\n",
      "   \u001b[0m%9 \u001b[0m= \u001b[96m\u001b[1mfadd\u001b[22m\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m \u001b[0m%5\u001b[0m, \u001b[0m%8\n",
      "\u001b[90m; └\u001b[39m\n",
      "  \u001b[0m%10 \u001b[0m= \u001b[96m\u001b[1mbitcast\u001b[22m\u001b[39m \u001b[33m[\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m]\u001b[39m\u001b[0m* \u001b[0m%0 \u001b[95mto\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m*\n",
      "  \u001b[96m\u001b[1mstore\u001b[22m\u001b[39m \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m \u001b[0m%9\u001b[0m, \u001b[33m<\u001b[39m\u001b[33m2\u001b[39m \u001b[0mx \u001b[36mdouble\u001b[39m\u001b[33m>\u001b[39m\u001b[0m* \u001b[0m%10\u001b[0m, \u001b[95malign\u001b[39m \u001b[33m8\u001b[39m\n",
      "  \u001b[96m\u001b[1mret\u001b[22m\u001b[39m \u001b[36mvoid\u001b[39m\n",
      "\u001b[33m}\u001b[39m\n",
      "\t\u001b[0m.text\n",
      "\t\u001b[0m.file\t\u001b[0m\"sumsquare\"\n",
      "\t\u001b[0m.globl\t\u001b[0mjulia_sumsquare_2536            \u001b[90m# -- Begin function julia_sumsquare_2536\u001b[39m\n",
      "\t\u001b[0m.p2align\t\u001b[33m4\u001b[39m\u001b[0m, \u001b[33m0x90\u001b[39m\n",
      "\t\u001b[0m.type\t\u001b[0mjulia_sumsquare_2536\u001b[0m,\u001b[0m@function\n",
      "\u001b[91mjulia_sumsquare_2536:\u001b[39m                   \u001b[90m# @julia_sumsquare_2536\u001b[39m\n",
      "\u001b[90m; ┌ @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X42sdnNjb2RlLXJlbW90ZQ==.jl:2 within `sumsquare`\u001b[39m\n",
      "\u001b[90m# %bb.0:                                # %top\u001b[39m\n",
      "\t\u001b[96m\u001b[1mpush\u001b[22m\u001b[39m\t\u001b[0mrbp\n",
      "\u001b[90m; │┌ @ intfuncs.jl:332 within `literal_pow`\u001b[39m\n",
      "\u001b[90m; ││┌ @ int.jl:88 within `*`\u001b[39m\n",
      "\t\u001b[96m\u001b[1mimul\u001b[22m\u001b[39m\t\u001b[0mrdi\u001b[0m, \u001b[0mrdi\n",
      "\t\u001b[96m\u001b[1mimul\u001b[22m\u001b[39m\t\u001b[0mrsi\u001b[0m, \u001b[0mrsi\n",
      "\t\u001b[96m\u001b[1mmov\u001b[22m\u001b[39m\t\u001b[0mrbp\u001b[0m, \u001b[0mrsp\n",
      "\u001b[90m; │└└\u001b[39m\n",
      "\u001b[90m; │┌ @ int.jl:87 within `+`\u001b[39m\n",
      "\t\u001b[96m\u001b[1mlea\u001b[22m\u001b[39m\t\u001b[0mrax\u001b[0m, \u001b[33m[\u001b[39m\u001b[0mrsi \u001b[0m+ \u001b[0mrdi\u001b[33m]\u001b[39m\n",
      "\t\u001b[96m\u001b[1mpop\u001b[22m\u001b[39m\t\u001b[0mrbp\n",
      "\t\u001b[96m\u001b[1mret\u001b[22m\u001b[39m\n",
      "\u001b[91m.Lfunc_end0:\u001b[39m\n",
      "\t\u001b[0m.size\t\u001b[0mjulia_sumsquare_2536\u001b[0m, \u001b[0m.Lfunc_end0-julia_sumsquare_2536\n",
      "\u001b[90m; └└\u001b[39m\n",
      "                                        \u001b[90m# -- End function\u001b[39m\n",
      "\t\u001b[0m.section\t\u001b[0m\".note.GNU-stack\"\u001b[0m,\u001b[0m\"\"\u001b[0m,\u001b[0m@progbits\n",
      "\t\u001b[0m.text\n",
      "\t\u001b[0m.file\t\u001b[0m\"sumsquare\"\n",
      "\t\u001b[0m.globl\t\u001b[0mjulia_sumsquare_2540            \u001b[90m# -- Begin function julia_sumsquare_2540\u001b[39m\n",
      "\t\u001b[0m.p2align\t\u001b[33m4\u001b[39m\u001b[0m, \u001b[33m0x90\u001b[39m\n",
      "\t\u001b[0m.type\t\u001b[0mjulia_sumsquare_2540\u001b[0m,\u001b[0m@function\n",
      "\u001b[91mjulia_sumsquare_2540:\u001b[39m                   \u001b[90m# @julia_sumsquare_2540\u001b[39m\n",
      "\u001b[90m; ┌ @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X42sdnNjb2RlLXJlbW90ZQ==.jl:1 within `sumsquare`\u001b[39m\n",
      "\u001b[90m# %bb.0:                                # %top\u001b[39m\n",
      "\t\u001b[96m\u001b[1mpush\u001b[22m\u001b[39m\t\u001b[0mrbp\n",
      "\u001b[90m; │┌ @ intfuncs.jl:332 within `literal_pow`\u001b[39m\n",
      "\u001b[90m; ││┌ @ float.jl:411 within `*`\u001b[39m\n",
      "\t\u001b[96m\u001b[1mvmulsd\u001b[22m\u001b[39m\t\u001b[0mxmm0\u001b[0m, \u001b[0mxmm0\u001b[0m, \u001b[0mxmm0\n",
      "\t\u001b[96m\u001b[1mvmulsd\u001b[22m\u001b[39m\t\u001b[0mxmm1\u001b[0m, \u001b[0mxmm1\u001b[0m, \u001b[0mxmm1\n",
      "\t\u001b[96m\u001b[1mmov\u001b[22m\u001b[39m\t\u001b[0mrbp\u001b[0m, \u001b[0mrsp\n",
      "\u001b[90m; │└└\u001b[39m\n",
      "\u001b[90m; │┌ @ float.jl:409 within `+`\u001b[39m\n",
      "\t\u001b[96m\u001b[1mvaddsd\u001b[22m\u001b[39m\t\u001b[0mxmm0\u001b[0m, \u001b[0mxmm0\u001b[0m, \u001b[0mxmm1\n",
      "\t\u001b[96m\u001b[1mpop\u001b[22m\u001b[39m\t\u001b[0mrbp\n",
      "\t\u001b[96m\u001b[1mret\u001b[22m\u001b[39m\n",
      "\u001b[91m.Lfunc_end0:\u001b[39m\n",
      "\t\u001b[0m.size\t\u001b[0mjulia_sumsquare_2540\u001b[0m, \u001b[0m.Lfunc_end0-julia_sumsquare_2540\n",
      "\u001b[90m; └└\u001b[39m\n",
      "                                        \u001b[90m# -- End function\u001b[39m\n",
      "\t\u001b[0m.section\t\u001b[0m\".note.GNU-stack\"\u001b[0m,\u001b[0m\"\"\u001b[0m,\u001b[0m@progbits\n",
      "\t\u001b[0m.text\n",
      "\t\u001b[0m.file\t\u001b[0m\"sumsquare\"\n",
      "\t\u001b[0m.globl\t\u001b[0mjulia_sumsquare_2542            \u001b[90m# -- Begin function julia_sumsquare_2542\u001b[39m\n",
      "\t\u001b[0m.p2align\t\u001b[33m4\u001b[39m\u001b[0m, \u001b[33m0x90\u001b[39m\n",
      "\t\u001b[0m.type\t\u001b[0mjulia_sumsquare_2542\u001b[0m,\u001b[0m@function\n",
      "\u001b[91mjulia_sumsquare_2542:\u001b[39m                   \u001b[90m# @julia_sumsquare_2542\u001b[39m\n",
      "\u001b[90m; ┌ @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X51sdnNjb2RlLXJlbW90ZQ==.jl:1 within `sumsquare`\u001b[39m\n",
      "\u001b[90m# %bb.0:                                # %top\u001b[39m\n",
      "\t\u001b[96m\u001b[1mpush\u001b[22m\u001b[39m\t\u001b[0mrbp\n",
      "\u001b[90m; │ @ /home/fra/repos/lessons/webinar_documents/2024-feb-02-webinar/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X51sdnNjb2RlLXJlbW90ZQ==.jl:2 within `sumsquare`\u001b[39m\n",
      "\u001b[90m; │┌ @ intfuncs.jl:332 within `literal_pow`\u001b[39m\n",
      "\u001b[90m; ││┌ @ float.jl:411 within `*`\u001b[39m\n",
      "\t\u001b[96m\u001b[1mvmovupd\u001b[22m\u001b[39m\t\u001b[0mxmm0\u001b[0m, \u001b[95mxmmword\u001b[39m \u001b[95mptr\u001b[39m \u001b[33m[\u001b[39m\u001b[0mrsi\u001b[33m]\u001b[39m\n",
      "\t\u001b[96m\u001b[1mvmovupd\u001b[22m\u001b[39m\t\u001b[0mxmm1\u001b[0m, \u001b[95mxmmword\u001b[39m \u001b[95mptr\u001b[39m \u001b[33m[\u001b[39m\u001b[0mrdx\u001b[33m]\u001b[39m\n",
      "\t\u001b[96m\u001b[1mmov\u001b[22m\u001b[39m\t\u001b[0mrbp\u001b[0m, \u001b[0mrsp\n",
      "\t\u001b[96m\u001b[1mmov\u001b[22m\u001b[39m\t\u001b[0mrax\u001b[0m, \u001b[0mrdi\n",
      "\t\u001b[96m\u001b[1mvmulpd\u001b[22m\u001b[39m\t\u001b[0mxmm0\u001b[0m, \u001b[0mxmm0\u001b[0m, \u001b[0mxmm0\n",
      "\t\u001b[96m\u001b[1mvmulpd\u001b[22m\u001b[39m\t\u001b[0mxmm1\u001b[0m, \u001b[0mxmm1\u001b[0m, \u001b[0mxmm1\n",
      "\u001b[90m; │└└\u001b[39m\n",
      "\u001b[90m; │┌ @ float.jl:409 within `+`\u001b[39m\n",
      "\t\u001b[96m\u001b[1mvaddpd\u001b[22m\u001b[39m\t\u001b[0mxmm0\u001b[0m, \u001b[0mxmm0\u001b[0m, \u001b[0mxmm1\n",
      "\u001b[90m; │└\u001b[39m\n",
      "\t\u001b[96m\u001b[1mvmovupd\u001b[22m\u001b[39m\t\u001b[95mxmmword\u001b[39m \u001b[95mptr\u001b[39m \u001b[33m[\u001b[39m\u001b[0mrdi\u001b[33m]\u001b[39m\u001b[0m, \u001b[0mxmm0\n",
      "\t\u001b[96m\u001b[1mpop\u001b[22m\u001b[39m\t\u001b[0mrbp\n",
      "\t\u001b[96m\u001b[1mret\u001b[22m\u001b[39m\n",
      "\u001b[91m.Lfunc_end0:\u001b[39m\n",
      "\t\u001b[0m.size\t\u001b[0mjulia_sumsquare_2542\u001b[0m, \u001b[0m.Lfunc_end0-julia_sumsquare_2542\n",
      "\u001b[90m; └\u001b[39m\n",
      "                                        \u001b[90m# -- End function\u001b[39m\n",
      "\t\u001b[0m.section\t\u001b[0m\".note.GNU-stack\"\u001b[0m,\u001b[0m\"\"\u001b[0m,\u001b[0m@progbits\n"
     ]
    }
   ],
   "source": [
    "# Surface level AST\n",
    "Meta.parse(\"sumsquare(1, 2)\") |> dump\n",
    "Meta.parse(\"sumsquare(p1, p2)\") |> dump\n",
    "\n",
    "# Lowered form of AST\n",
    "@code_lowered sumsquare(1, 2)\n",
    "@code_lowered sumsquare(p1, p2)\n",
    "\n",
    "# Type-inferred lowered form of AST\n",
    "@code_typed sumsquare(1, 2)\n",
    "@code_typed sumsquare(1.0, 2.0)\n",
    "@code_typed sumsquare(p1, p2)\n",
    "\n",
    "# Lowered and type-inferred ASTs\n",
    "@code_warntype sumsquare(1.0, 2.0)\n",
    "@code_warntype sumsquare(p1, p2)\n",
    "\n",
    "# LLVM intermediate representation:\n",
    "@code_llvm sumsquare(1, 2)\n",
    "@code_llvm sumsquare(1.0, 2.0)\n",
    "@code_llvm sumsquare(p1, p2)\n",
    "\n",
    "# native assembly instructions:\n",
    "@code_native sumsquare(1, 2)\n",
    "@code_native sumsquare(1.0, 2.0)\n",
    "@code_native sumsquare(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb40f18-6fa6-40e3-bb48-5f398dbbd9ac",
   "metadata": {},
   "source": [
    "## Metaprogramming\n",
    "\n",
    "Julia represents its own code as a data structure accessible from the language itself. Since code is represented by objects that can be created and manipulated from within the language, it is possible for a program to transform and generate its own code, that is to create powerful macros (the term \"metaprogramming\" refers to the possibility to write code that writes code that is then evaluated).\n",
    "\n",
    "Note the difference from C or C++ macros. There, macros work performing textual manipulation and substitution before any actual parsing or interpretation occurs.\n",
    "\n",
    "In Julia, macros work when the code has already been parsed and organised in a syntax tree, and hence the semantic is much richer and allows for much more powerful manipulations.\n",
    "\n",
    "More reading materials for the metaprogramming\n",
    "- [Documentation on metaprogramming](https://docs.julialang.org/en/v1/manual/metaprogramming/)\n",
    "- [Metaprogramming tutorial from JuliaCon21](https://github.com/dpsanders/Metaprogramming_JuliaCon_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26000d12-9ec2-4ad5-a34a-b91585862370",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. GPU programming using Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2811fe-dcdb-44ca-b9b1-c5589aeacbac",
   "metadata": {},
   "source": [
    "Julia has first-class support for GPU programming through the following packages that target GPUs from all major vendors:\n",
    "- [CUDA.jl](https://cuda.juliagpu.org/stable/) for NVIDIA GPUs\n",
    "- [AMDGPU.jl](https://amdgpu.juliagpu.org/stable/) for AMD GPUs\n",
    "- [oneAPI.jl](https://github.com/JuliaGPU/oneAPI.jl) for Intel GPUs\n",
    "- [Metal.jl](https://github.com/JuliaGPU/Metal.jl) for Apple M-series GPUs\n",
    "\n",
    "ENCCS reading materials:\n",
    "- [GPU Programming: When, Why and How?](https://enccs.github.io/gpu-programming/6-language-support/#julia)\n",
    "- [Julia for High-Performance Scientific Computing](https://enccs.github.io/julia-for-hpc/GPU/)\n",
    "- [Julia for High-Performance Data Analytics](https://enccs.github.io/julia-for-hpda/)\n",
    "\n",
    "Moreover, the [KernelAbstractions.jl](https://juliagpu.github.io/KernelAbstractions.jl/stable/) package can be useful to write vendor-agnostic code that can execute on different GPU brands (and also fallback on CPUs if necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da2de8-54b5-4fbd-97d2-281af7fa5857",
   "metadata": {},
   "source": [
    "## Setup and Access to GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0432bc-e4b5-4ccb-a9d2-1e4fbc3972b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I have an AMDGPU so I need the AMDGPU.jl package\n",
    "using Pkg\n",
    "Pkg.add(\"KernelAbstractions\")\n",
    "Pkg.add(\"AMDGPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46612e04-b392-4ac1-8c4f-ee4ddb2393c7",
   "metadata": {},
   "source": [
    "## The Array interface\n",
    "\n",
    "GPU programming with Julia can be as simple as using a different array type instead of regular Base.Array. \n",
    "\n",
    "For Apple M-series GPUs, it should use `ROCArray` from `AMDGPU.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75922a4c-bd6c-4e0e-a837-9f7a2692f686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using AMDGPU\n",
    "\n",
    "# copy an array to GPU and executes a simple operation on GPU\n",
    "A_d = ROCArray([1,2,3,4])\n",
    "A_d .+= 1\n",
    "\n",
    "# fetch data from GPU to CPU\n",
    "A = Array(A_d) # the overhead of copying data to GPU makes such simple calculations very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e94c9-d41f-4a37-9c65-e3776501fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A code example for matrix multiplication\n",
    "using BenchmarkTools\n",
    "using AMDGPU\n",
    "\n",
    "A = rand(Float32, 2^9, 2^9); # Float64 does not work for Apple GPU\n",
    "A_d = ROCArray(A);\n",
    "\n",
    "@btime $A * $A;\n",
    "\n",
    "@btime AMDGPU.@sync $A_d * $A_d;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673446f-941c-43da-892a-4f9466920958",
   "metadata": {},
   "source": [
    "## Writing your own kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5cf8c-cc0a-4634-90de-1df0dac5204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function vadd!(C, A, B)\n",
    "    for i in 1:length(A)\n",
    "        @inbounds C[i] = A[i] + B[i]\n",
    "    end\n",
    "end\n",
    "\n",
    "A = zeros(10) .+ 3.0;\n",
    "B = ones(10) .* 2;\n",
    "C = similar(B);\n",
    "vadd!(C, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7ace8-fad4-4738-addd-55155e4aa649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of vector addition kernel for Apple GPU\n",
    "\n",
    "A_d = MtlArray(Float32.(A));\n",
    "B_d = MtlArray(Float32.(B));\n",
    "C_d = similar(B_d);\n",
    "\n",
    "# WARNING: the kernel above is not suitable for launching on GPUs\n",
    "@metal vadd!(C_d, A_d, B_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea45a38-18b5-4844-9c4e-ffb5f160af06",
   "metadata": {},
   "source": [
    "**NOTE**: the *performance is terrible* for the code above, because each thread on the GPU is performing the same loop! To split work among the GPU cores, we have to remove the loop over all elements and instead use special functions which, when called by each GPU thread, return a unique index. For Metal.jl we use `thread_position_in_grid_1d()`, while the corresponding function for CUDA.jl is `threadIdx()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885832d-ca2f-447b-a553-8faa4fa75d76",
   "metadata": {},
   "source": [
    "![](https://enccs.github.io/julia-for-hpc/_images/MappingBlocksToSMs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516a9d7-391c-470e-b5b8-0b1353320224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing for-loop with thread_position_in_grid_1d()\n",
    "function vadd!(C, A, B)\n",
    "    index = thread_position_in_grid_1d()\n",
    "    @inbounds C[index] = A[index] + B[index]\n",
    "    return\n",
    "end\n",
    "\n",
    "A = MtlArray(Float32.(ones(Float32, 2^9)*2));\n",
    "B = MtlArray(Float32.(ones(Float32, 2^9)*3));\n",
    "C = similar(A);\n",
    "\n",
    "N = length(A)\n",
    "println(\"length of matrix A = \", N)\n",
    "@metal threads=N vadd!(C, A, B)\n",
    "\n",
    "@assert all(Array(C) .== 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9f340-2cf8-4900-b6c4-9cebbb0d1c6a",
   "metadata": {},
   "source": [
    "However, this implementation will not work for arrays that are larger than the maximum number of threads in a block - try increasing the size to `2^12`! \n",
    "\n",
    "Clearly, GPUs have a limited number of threads they can run on a single SM. To parallelise over multiple SMs we need to run a kernel with multiple blocks where we also take advantage of the `blockDim()` and `blockIdx()` functions (in the case of NVIDIA). Here's how it looks for CUDA.jl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4eef2-a5de-4ff2-a766-939dc13f1954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this example is for CUDA.jl (requires CUDA-compatible NVIDIA GPUs)\n",
    "function vadd!(C, A, B)\n",
    "    i = threadIdx().x + (blockIdx().x - 1) * blockDim().x\n",
    "    if i <= length(A)\n",
    "        @inbounds C[i] = A[i] + B[i]\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "A, B = CuArray(ones(2^9)*2), CuArray(ones(2^9)*3);\n",
    "C = similar(A);\n",
    "\n",
    "nthreads = 256\n",
    "# smallest integer larger than or equal to length(A)/threads\n",
    "numblocks = cld(length(A), nthreads)\n",
    "println(\"nthreads = \", nthreads, \", numblocks = \", numblocks)\n",
    "\n",
    "# run using 256 threads\n",
    "@cuda threads=nthreads blocks=numblocks vadd!(C, A, B)\n",
    "\n",
    "@assert all(Array(C) .== 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdb760-0fcc-4d9c-87cd-748ae7178db3",
   "metadata": {},
   "source": [
    "**Restrictions in kernel programming**\n",
    "\n",
    "Within kernels, most of the Julia language is supported with the exception of functionality that requires the Julia runtime library. This means one cannot allocate memory or perform dynamic function calls, both of which are easy to do accidentally!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b9040-5f29-44ef-b745-cb5f80c4276e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Julia packages for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe842a-2ed1-4446-99ef-bf1b29122369",
   "metadata": {},
   "source": [
    "The `MLJ.jl` (https://github.com/alan-turing-institute/MLJ.jl) package provides a unified interface to common machine learning algorithms, which include `generalized linear models`, `decision trees`, and `clustering`.\n",
    "\n",
    "`Flux.jl` (https://github.com/FluxML/Flux.jl) and `Knet.jl` (https://github.com/denizyuret/Knet.jl) are powerful packages for Deep Learning.\n",
    "\n",
    "Packages such as `Metalhead.jl`(https://github.com/FluxML/Metalhead.jl), `ObjectDetector.jl`(https://github.com/r3tex/ObjectDetector.jl), and `TextAnalysis.jl`(https://github.com/JuliaText/TextAnalysis.jl) provide ready to use pre-trained models for common tasks.\n",
    "\n",
    "`AlphaZero.jl`(https://github.com/jonathan-laurent/AlphaZero.jl) provides a high performance implementation of the reinforcement learning algorithms from AlphaZero.\n",
    "\n",
    "`Turing.jl`(https://turinglang.org/stable/) is a best in class package for probabilistic programming.\n",
    "\n",
    "More packages for AI & ML from Julia official website\n",
    "- ML: https://juliapackages.com/c/machine-learning\n",
    "- NLP: https://juliapackages.com/c/nlp\n",
    "- Neural Networks: https://juliapackages.com/c/neural-networks\n",
    "- Reinforcement Learning: https://juliapackages.com/c/reinforcement-learning\n",
    "- Supervised Learning: https://juliapackages.com/c/supervised-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ea560-8d88-49cc-b360-fd800c3434fb",
   "metadata": {},
   "source": [
    "### Training a deep neural network to classify penguins using `Flux.jl`\n",
    "\n",
    "Flux.jl comes “batteries-included” with many useful tools built in, but also enables the user to write own Julia code for DL components.\n",
    "- Flux has relatively few explicit APIs for features like regularisation or embeddings.\n",
    "- All of Flux is straightforward Julia code and it can be worth to inspect and extend it if needed.\n",
    "- Flux works well with other Julia libraries, like dataframes, images and differential equation solvers. One can build complex data processing pipelines that integrate Flux models.\n",
    "\n",
    "To train a model we need four things:\n",
    "- A collection of data points that will be provided to the objective function.\n",
    "- A objective (cost or loss) function, that evaluates how well a model is doing given some input data.\n",
    "- The definition of a model and access to its trainable parameters.\n",
    "- An optimiser that will update the model parameters appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3b6cb-06de-4b07-85a7-e495aa67f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"MLJ\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"PalmerPenguins\")\n",
    "Pkg.add(\"StatsBase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c71ea0-f659-46b4-b7ba-0a92057ddbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "using MLJ: partition, ConfusionMatrix\n",
    "using DataFrames\n",
    "using PalmerPenguins\n",
    "\n",
    "table = PalmerPenguins.load()\n",
    "df = DataFrame(table)\n",
    "dropmissing!(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e592536f-d4a7-4849-b21b-c1aed2979b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of the Penguins dataset and making it suitable for training a network.\n",
    "\n",
    "# select feature and label columns\n",
    "X = select(df, Not([:species, :sex, :island]))\n",
    "Y = df[:, :species]\n",
    "\n",
    "# split into training and testing parts\n",
    "(xtrain, xtest), (ytrain, ytest) = partition((X, Y), 0.8, shuffle=true, rng=123, multi=true)\n",
    "\n",
    "# use single precision and transpose arrays\n",
    "xtrain, xtest = Float32.(Array(xtrain)'), Float32.(Array(xtest)')\n",
    "\n",
    "# one-hot encoding\n",
    "ytrain = Flux.onehotbatch(ytrain, [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "ytest = Flux.onehotbatch(ytest, [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "\n",
    "# count penguin classes to see if it's balanced\n",
    "sum(ytrain, dims=2)\n",
    "sum(ytest, dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac46d1-2923-4b51-ae7a-d405685b5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define `model` to be the neural network.\n",
    "\n",
    "n_features, n_classes, n_neurons = 4, 3, 10\n",
    "model = Chain(\n",
    "        Dense(n_features, n_neurons),\n",
    "        BatchNorm(n_neurons, relu),\n",
    "        Dense(n_neurons, n_classes),\n",
    "        softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c86ddc-c7e8-4ed1-b0c5-1a15d1e6900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a `loss` function which will be minimized during training.\n",
    "# Herein we use cross-entropy loss function typically used for classification\n",
    "loss(x, y) = Flux.crossentropy(model(x), y)\n",
    "\n",
    "# Define another function presenting the accuracy of the model\n",
    "# onecold (opposite to onehot) gives back the original representation\n",
    "function accuracy(x, y)\n",
    "    return sum(Flux.onecold(model(x)) .== Flux.onecold(y)) / size(y, 2)\n",
    "end\n",
    "\n",
    "# check accuracy before training\n",
    "accuracy(xtrain, ytrain)\n",
    "accuracy(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fbef2-31a5-401e-9ac6-41ae8c8d88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase: sample\n",
    "\n",
    "# Instead of training the entire dataset, training data were divided into `minibatches` and \n",
    "# update network weights on each minibatch separately.\n",
    "function create_minibatches(xtrain, ytrain, batch_size=32, n_batch=10)\n",
    "    minibatches = Tuple[]\n",
    "    for i in 1:n_batch\n",
    "        randinds = sample(1:size(xtrain, 2), batch_size)\n",
    "        push!(minibatches, (xtrain[:, randinds], ytrain[:,randinds]))\n",
    "    end\n",
    "    return minibatches\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc84d8-ab8a-4e7e-8974-8871316abcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define an anonymous `callback` function to pass into the training function to monitor the progress, \n",
    "# to select standard ADAM optimizer, and to extract parameters of the model.\n",
    "\n",
    "callback = () -> @show(loss(xtrain, ytrain))\n",
    "opt = ADAM()\n",
    "θ = Flux.params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f54b1-e23d-48eb-ba90-3b1370618b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is to create the `minibatches` to call the `create_minibatches` function defined above.\n",
    "minibatches = create_minibatches(xtrain, ytrain)\n",
    "\n",
    "# We run 100 epochs to train the model.\n",
    "for i in 1:100\n",
    "    # train on minibatches\n",
    "    Flux.train!(loss, θ, minibatches, opt, cb = Flux.throttle(callback, 1));\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595db393-2f88-4a1d-bc73-2ec8b7f5a628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check final accuracy\n",
    "\n",
    "accuracy(xtrain, ytrain)\n",
    "accuracy(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0297612-c2eb-4900-b944-c0210932acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we create a confusion matrix to quantify the performance of the model.\n",
    "\n",
    "predicted_species = Flux.onecold(model(xtest), [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "true_species = Flux.onecold(ytest, [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "ConfusionMatrix()(predicted_species, true_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5f89a-005c-45ae-962e-aa422bb2ba9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
