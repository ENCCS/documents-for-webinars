{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2baa74-a09a-40e6-88f7-039199bde853",
   "metadata": {},
   "source": [
    "# Python Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfabd38-0359-4540-9f1f-f57a9862ede9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Introduction to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2083379-21fc-4a9a-bef6-f61eafee7fa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "::::{hint} Prerequisites\n",
    "\n",
    ":::{dropdown} **Scalar variables**: integers (`int`), floating point numbers (`float`), strings (`str`), *etc.*\n",
    "\n",
    "```python\n",
    "42  # int\n",
    "1.0  # float\n",
    "'these'\n",
    "\"are\"\n",
    "\"\"\"all\n",
    "valid strings.\"\"\"\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{dropdown} **Collections**: `list`, `tuple`, `dict`, `set`, *etc.*\n",
    "\n",
    "```python\n",
    ">>> # Lists: are mutable ordered-sequences\n",
    ">>> my_things = [1, 2, 'banana']\n",
    ">>> my_things.append(3.14)\n",
    ">>> my_things\n",
    "[1, 2, 'banana', 3.14]\n",
    "```\n",
    "```python\n",
    ">>> # Tuples: are immutable ordered-sequences\n",
    ">>> truthy_values = ('yes', 'ja', True, 1.0)\n",
    ">>> del truthy_values[0]\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "TypeError: 'tuple' object doesn't support item deletion\n",
    "```\n",
    "```python\n",
    ">>> # Dictionaries: key-value pairs or hash-maps\n",
    ">>> game_status = {\"jill\": 99, \"t-rex\": \"RIP\"}\n",
    "```\n",
    "```python\n",
    ">>> # Sets: unique unordered sequences\n",
    ">>> fruits = {\"apple\", \"banana\", \"banana\"}\n",
    ">>> fruits\n",
    "{'apple', 'banana'}\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{dropdown} **Control structures**: `if-elif-else`, `for` loop, `while` loop, *etc.*\n",
    "\n",
    "```python\n",
    "\n",
    "# Conditional expressions\n",
    "if 0.5 > schrödingers_cat > 1.0:\n",
    "    print(\"Alive\")\n",
    "elif 0. > schrödingers_cat >= 0.5:\n",
    "    print(\"Dead\")\n",
    "else:\n",
    "    print(\"Undead\")\n",
    "\n",
    "# Loops\n",
    "for i_day in range(365):\n",
    "    print(\"Hi, good morning!\")\n",
    "\n",
    "while True:\n",
    "    print(\"Na\", end=\"\")\n",
    "    if input() == \"stop\":\n",
    "        break\n",
    "print(\"Batman!\")\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} **Functions**: built-in functions (`len`, `type`, ...) and user-defined functions.\n",
    "\n",
    "```python\n",
    ">>> greeting = \"hello world\"\n",
    ">>> len(greeting)\n",
    "11\n",
    ">>> type(greeting)\n",
    "<class 'str'>\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{dropdown} **Decorators**: special syntax which modifies the behaviour of a function or a class.\n",
    ":class: dropdown\n",
    "\n",
    "```python\n",
    "@something\n",
    "def foo():\n",
    "    ...\n",
    "```\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "- `functools.lru_cache` for an example of a decorator,\n",
    "- `functools.wraps` and `contextlib.contextmanager` to create your own decorators.\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "Python also uses and encourages us to structure code using\n",
    "- Type annotations: hints which can be used by a type-checker or a compiler.\n",
    "- Class: simple encapsulation, inheritance, *etc.*\n",
    "- Modules: a `.py` file containing a valid Python code. Typically does not execute anything on import.\n",
    "- Package: an installable, re-usable collection of modules and other files, distributable via PyPI or conda-forge\n",
    "\n",
    "**but this is not necessary for the purpose of this webinar.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82d9b4-c725-4da7-a7b2-4cf24c7588e0",
   "metadata": {},
   "source": [
    "::::{hint} Jupyter and IPython \n",
    "\n",
    "This webinar is demonstrated on a Jupyter notebook, which uses an IPython (Interactive Python) kernel (a console running in the background).\n",
    "All Python syntax are valid in IPython and on top of that it has some special features.\n",
    "\n",
    "Here, we will make use of the special variable `_` and **magic commands** ✨ `%time`, `%timeit` and `%%timeit`.\n",
    "\n",
    ":::: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d5a4c-886f-48b2-a7a9-4beea9e37d99",
   "metadata": {},
   "source": [
    "Special variable `_` stores the value of the previous output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546eab83-e1d5-4ec2-992e-35a168fa53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e539fe4-bf17-4ec6-879f-307c72e6e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e419f-7301-4353-a826-5e549022f4ed",
   "metadata": {},
   "source": [
    "Line magic `%time` records the wall-time for executing a Python expression _once_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04edfb5-9576-4406-9df1-09cbdae2146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sum(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a678eb-25d8-4320-96ce-a583e08adba8",
   "metadata": {},
   "source": [
    "Line magic `%timeit` let's you do a micro-benchmark of a single Python expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4a704-1c64-4d6b-897c-fb4710af5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = list(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b881b7e-4eb2-4cef-ae23-426c271728d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit sum(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94131d07-ebe0-4fcd-a1a9-abad855fba72",
   "metadata": {},
   "source": [
    "It can be also used as cell-magic `%%timeit` which does a micro-benchmark of a block of Python expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b472f-789b-470a-91c8-0dd2f5af3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "total = 1\n",
    "for i in range(90):\n",
    "    total += i / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c6550-0f01-4b54-840e-56bdca1d76af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Numpy, Pandas, Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7db53-e450-434b-ab49-729204ad130d",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code for display_timings()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_timings(**kwargs):\n",
    "    nrows = len(kwargs)\n",
    "    fig, ax = plt.subplots(figsize=(8, min(nrows, 8)))\n",
    "    keys = list(kwargs)\n",
    "    fmt_keys = [k.replace(\"_\", \" \") for k in kwargs]\n",
    "    i_keys = list(range(len(keys)))\n",
    "\n",
    "    ax.barh(i_keys, times := [kwargs[key].average for key in keys])\n",
    "    ax.errorbar(times, i_keys, xerr=[kwargs[key].stdev for key in keys], fmt=\"ro\")\n",
    "    ax.set(xscale=\"log\", xlabel=\"avg. wall time (seconds)\")\n",
    "    axis = plt.gca()\n",
    "    axis.set_yticks(i_keys, fmt_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56cce2a-ce7e-4eab-947c-38fce97c6e29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b38be-3f54-4250-ac43-4e90930f3a34",
   "metadata": {},
   "source": [
    ":::{important}`NumPy` is a Python library for arrays\n",
    "It can be used to perform a wide variety of (efficient) mathematical operations and linear algebra on arrays and matrices.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5384d75-b9c5-4cf9-9212-19bcc8c0de9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = list(range(10000))\n",
    "b = [0] * 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ff3be-4950-4e6d-b1bd-a58e3896b91f",
   "metadata": {},
   "source": [
    "Why should use **loops**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b3bca-9c3d-4335-b794-2bd5d7271b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -q -o\n",
    "for i in range(len(a)):\n",
    "    b[i] = a[i] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a58903-1e0c-4265-abcd-3f23b387a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_loops = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac5f0b-b658-4f6e-bc99-f1599cbfe025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2912549-bdbc-4b14-9526-68e304eb42cb",
   "metadata": {},
   "source": [
    "... when you can **vectorize**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86469330-2d6c-4328-9660-bd94a21b8485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -q -o\n",
    "b = a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053bf14-a977-4b73-921e-0e447355135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vec = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59766bb7-2048-441c-adeb-8749c4fb7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_timings(loops_over_lists=time_loops, vectorized_math_with_arrays=time_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d081ff9-356d-4204-aba7-6c666ac14c92",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Numpy is often imported as `np` and this is common convention.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d5829f-7475-4099-b2a1-808e5e43e205",
   "metadata": {},
   "source": [
    "#### Creating arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9010b-f411-45c1-9b8e-709b24e7174e",
   "metadata": {},
   "source": [
    "Python sequences such as lists or tuples can be **transformed** into a Numpy array.\n",
    "\n",
    "Numpy arrays can be **1D, 2D, .... n-dimensional**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703be7b6-58ed-4a0e-991e-23f57a9d50a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])  # 1-dimensional array (rank 1)\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]])  # 2-dimensional array (rank 2)\n",
    "\n",
    "print(b.shape)  # the shape (rows,columns)\n",
    "print(b.size)  # number of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae34ec8-feed-41fa-9688-a2a8d1b5e05b",
   "metadata": {},
   "source": [
    "It is often **homogenous**, that is made of a single data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bb5cc-def3-4b1f-b009-be0e63bde302",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264353de-08ab-4ff5-8e15-30f81920590a",
   "metadata": {},
   "source": [
    "Arrays can also be **generated**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b17fe-dcd1-4a3b-bf9b-868640436e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(3)  # Identity \"matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6731d-54fa-4c5f-8045-157af6659ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(16)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570222e7-2d00-4429-a152-5567739ac3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = a.reshape(4, 4)\n",
    "\n",
    "b = np.random.rand(16).reshape(4, 4)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ba29a-5359-464e-9575-43c0b8482972",
   "metadata": {},
   "source": [
    "#### Array maths and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab88137-9c85-4f38-8205-4aba812afcac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = np.add(a, b)  # equivalent to `a + b`\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501b227-3d36-461f-be59-23cd8bc8b3b8",
   "metadata": {},
   "source": [
    "Other common mathematical operations include:\n",
    "- elementwise operations:\n",
    "    - `-` (numpy.subtract)\n",
    "    - `*` (numpy.multiply)\n",
    "    - `/` (numpy.divide)\n",
    "    - `**` (numpy.pow())\n",
    "- `.T` (numpy.transpose())\n",
    "- `np.sqrt()`, `np.sum()`, `np.mean()`, `np.std()`, `np.max()`, `np.min()`\n",
    "- `@` (np.dot() / np.matmul())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7221d-50fd-4e03-93d1-58bd52848e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matrix multiplication\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97f178-08d1-4dd0-a69e-82c768eadb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.dot(a, b)  # equals to `a @ b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bff41-90c4-4bb9-a85d-90630ff1ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635d344-dbfd-422e-9df8-de40df77a1ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621a8c9-7601-4373-8924-8071d265ad3e",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{important}`Pandas` is for tabular data\n",
    "\n",
    "It is provides intuitive data structures for functions for reading in, manipulating and\n",
    "performing high-performance data analysis of tabular data.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622ac05-2920-4ce2-a8fa-24fa42b5a736",
   "metadata": {},
   "source": [
    "#### Code example to analyze the Titanic passenger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a44bd7-6ead-4cc1-bc3e-2e8eeffcdf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\n",
    "titanic = pd.read_csv(url, index_col=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747689f-7544-498d-806b-dc599f490668",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14fbe71-913e-423f-8414-e2e04e0105b9",
   "metadata": {},
   "source": [
    "Tabular data can be **heterogenous**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e33ad-b673-4f24-85ba-d5615a932d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b97f1b-c2ed-413b-89ea-821425dd170a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the first 5 lines of the dataframe\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b37dbc-524c-42a2-a883-bfb83897ed33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print summary statistics for each column\n",
    "\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a46d590-bbef-45d7-92dc-1d9a533ed7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic[[\"Age\", \"Sex\", \"Survived\", \"Pclass\"]].groupby([\"Survived\", \"Sex\"]).aggregate(\n",
    "    \"median\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb254fe5-6f18-4051-862e-f227900a0c0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c6107-9fe9-4f1b-8f73-c7cf8567f26f",
   "metadata": {},
   "source": [
    "`Matplotlib` is a comprehensive library for creating static, animated, and interactive visualizations in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05109d4f-ac98-4e95-b7d8-8e9c761fa7a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualization of the Titanic passenger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24276b-9446-44cc-960b-53a6f253ddaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.hist(\n",
    "    [\n",
    "        titanic[titanic[\"Survived\"] == 1][\"Age\"],\n",
    "        titanic[titanic[\"Survived\"] == 0][\"Age\"],\n",
    "    ],\n",
    "    stacked=True,\n",
    "    bins=30,\n",
    "    label=[\"Survived\", \"Dead\"],\n",
    ")\n",
    "plt.xlabel(\"Age (in Years)\")\n",
    "plt.ylabel(\"Number of passengers on Titanic\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86f718-9f4f-4aa3-a9a8-1983f051c894",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GPU Programming using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db510a0-d3e6-4864-8c27-e87386ed8ad1",
   "metadata": {
    "tags": []
   },
   "source": [
    "There are several options available to work with python for GPU programming.\n",
    "- [GPU Programming: When, Why and How?](https://enccs.github.io/gpu-programming/)\n",
    "- [GPU Programming (Carpentries)](https://arc.leeds.ac.uk/lesson-gpu-programming/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44193981-5339-405c-a4b8-d6e679f531ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. **`cuDF`** and **`cuML`** libraries in ![RAPIDS](img/RAPIDS-logo.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aedb46c8-5d82-4d11-8f8e-9297721623b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    ":::{important} [RAPIDS](https://rapids.ai/) is a high-level package collection\n",
    "\n",
    "It implements CUDA functionalities and API with Python bindings.\n",
    "\n",
    "**It only supports NVIDIA GPUs.**\n",
    "\n",
    "- **`cuDF`** is the dataframe library for manipulating tabular datasets using GPU. cuDF provides a **Pandas**-like API for loading, joining, aggregating, filtering, and manipulating data.\n",
    "- **`cuML`** is a suite of libraries that implement algorithms and mathematical primitives functions to train machine learning models on your data to make predictions, similar to the **`scikit-learn`** API.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb16ef6-4141-4aad-9f07-22ca6ee7506b",
   "metadata": {},
   "source": [
    "### 1.1 Timing the Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab14ab7-fc4b-4fdb-a828-4081f45295a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit titanic[[\"Age\", \"Sex\", \"Survived\", \"Pclass\"]].groupby([\"Survived\", \"Sex\"]).aggregate(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd6809-5b1c-4172-be70-aeb46de816ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\n",
    "titanic_gpu = cudf.read_csv(url, index_col=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c024b-59b3-4df5-a2e6-cc2e1f59744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit titanic_gpu[[\"Age\", \"Sex\", \"Survived\", \"Pclass\"]].groupby([\"Survived\", \"Sex\"]).aggregate(\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae0fec-5801-4996-9e6a-a91e035cc70c",
   "metadata": {
    "user_expressions": [
     {
      "expression": "titanic.memory_usage().sum() / 1024",
      "result": {
       "ename": "NameError",
       "evalue": "name 'titanic' is not defined",
       "status": "error",
       "traceback": [
        "\u001b[0;31mNameError\u001b[0m\u001b[0;31m:\u001b[0m name 'titanic' is not defined\n"
       ]
      }
     }
    ]
   },
   "source": [
    ":::{hint} GPU version was slower. Why?\n",
    "\n",
    "1. The size of the data needs to be justifiably big for a GPU to be more performant than a CPU. The data is only {eval}`titanic.memory_usage().sum() / 1024` KB big.\n",
    "2. Aggregation cannot be efficiently parallized\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f52fb-1841-414d-ad5a-16d498602085",
   "metadata": {},
   "source": [
    "### 1.2 Timing the Taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7d26d-f3c0-4d45-9951-f226477d1770",
   "metadata": {},
   "source": [
    "Lets try to analyze NYC taxi data from <https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page> to compute median trip duration.\n",
    "\n",
    "Dictionary of the data: <https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f478c7-3398-4787-9b81-a29457e18823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trips = pd.read_parquet(\"./yellow_tripdata_2024-07.parquet\")\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55597c2d-7c35-4861-89d7-cd8885fe197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31f54f-7903-4967-af3f-beb209dc1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_duration = %timeit -o (trips.tpep_dropoff_datetime - trips.tpep_pickup_datetime).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee85fdf-8324-4e53-9e6b-8628b8802677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "trips_gpu = cudf.read_parquet(\"./yellow_tripdata_2024-07.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2370723f-e225-4740-93b7-ae36cd8ab936",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_duration_gpu = %timeit -o (trips_gpu.tpep_dropoff_datetime - trips_gpu.tpep_pickup_datetime).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc9c9f-ef21-4f5a-a837-00024cd94d6a",
   "metadata": {},
   "source": [
    "**How about an aggregate operation as before?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681de39-b4e9-4d3e-858a-1778fb673f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agg = %timeit -o trips[[\"passenger_count\", \"trip_distance\", \"RatecodeID\", \"total_amount\"]].groupby([\"RatecodeID\"]).aggregate(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15367541-3768-4d72-b43d-3213063b6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agg_gpu = %timeit -o trips_gpu[[\"passenger_count\", \"trip_distance\", \"RatecodeID\", \"total_amount\"]].groupby([\"RatecodeID\"]).aggregate(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa4227-5040-42a9-8cf6-c78d51df5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_timings(\n",
    "    aggregate=time_agg,\n",
    "    aggregate_gpu=time_agg_gpu,\n",
    "    trip_duration=time_duration,\n",
    "    trip_duration_gpu=time_duration_gpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd8e1b-0484-4724-bac3-6c012994e3c0",
   "metadata": {
    "user_expressions": [
     {
      "expression": "trips.memory_usage().sum() / 1024**2",
      "result": {
       "ename": "NameError",
       "evalue": "name 'trips' is not defined",
       "status": "error",
       "traceback": [
        "\u001b[0;31mNameError\u001b[0m\u001b[0;31m:\u001b[0m name 'trips' is not defined\n"
       ]
      }
     }
    ]
   },
   "source": [
    ":::{hint} Now, the GPU version was faster. Why?\n",
    "\n",
    "1. The data for NYC Yellow taxis is {eval}`trips.memory_usage().sum() / 1024**2` **MB** big which is a moderately big dataset.\n",
    "2. Even for the aggregate method, we see a modest performance gain.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57883fb-bf05-4222-a963-4ba133a9c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "del titanic, titanic_gpu, trips, trips_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c15c2d-211c-48e2-a6c2-603f10f63c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38f731-22fd-43f8-b527-a9458091b77a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216688a2-4cf2-4afd-b0c8-97e9c774a548",
   "metadata": {},
   "source": [
    ":::{important} `Numba` is an open-source just-in-time (JIT) compiler\n",
    "\n",
    "- It translates a subset of Python and NumPy into fast machine code using LLVM.\n",
    "- `Numba` offers options for parallelising Python code for CPUs and GPUs, with minor code changes.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8dc43d-04d4-44d7-b823-ff6e9e55161f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 `numba.jit()` decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be56abb-717a-422a-805f-cf82b9bc6170",
   "metadata": {},
   "source": [
    "Numba provides several utilities for code generation, and its central feature is the `numba.jit()` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e4a76-9f9e-4fc0-97d7-cac700faa4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mx = np.arange(10000).reshape(100, 100)\n",
    "\n",
    "\n",
    "def go_slow(a):  # Function is compiled and runs in machine code\n",
    "    result = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        result += np.sin(a[i, i])\n",
    "    return result\n",
    "\n",
    "\n",
    "time_slow = %timeit -o go_slow(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc71d6-a839-4046-8fc7-d50106e6e38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a):\n",
    "    result = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        result += np.sin(a[i, i])\n",
    "    return result\n",
    "\n",
    "\n",
    "time_fast = %timeit -o go_fast(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a37ab-6f3b-4a7a-b6f2-0d73770d70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_timings(go_slow=time_slow, go_fast=time_fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51dc921-49e6-4b65-ba2a-15bfaade47ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 `ufunc` and `gufunc`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26f85d-ef37-4660-964a-0dac2ece4710",
   "metadata": {},
   "source": [
    "Another feature of Numba is to generate NumPy universal functions.\n",
    "\n",
    "There are two types of universal functions:\n",
    "- Those which operate on scalars are “universal functions” (`ufunc`), which are achieved via `@vectorize` decorator\n",
    "- Those which operate on higher dimensional arrays and scalars are “generalized universal functions” (`gufunc`), which are achived via `@guvectorize` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6807c5c-9d1d-4bf8-9793-55f45e9ae33d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "\n",
    "# a simple version without using numba\n",
    "def func_cpu(x, y):\n",
    "    return math.pow(x, 3.0) + 4 * math.sin(y)\n",
    "\n",
    "\n",
    "@np.vectorize(otypes=[float])\n",
    "def func_numpy_cpu(x, y):\n",
    "    return math.pow(x, 3.0) + 4 * math.sin(y)\n",
    "\n",
    "\n",
    "# def func_numpy(x, y):\n",
    "#     return np.pow(x, 3.0) + 4 * np.sin(y)\n",
    "\n",
    "\n",
    "@numba.vectorize([numba.float64(numba.float64, numba.float64)], target=\"cpu\")\n",
    "def func_numba_cpu(x, y):\n",
    "    return math.pow(x, 3.0) + 4 * math.sin(y)\n",
    "\n",
    "\n",
    "@numba.vectorize([numba.float64(numba.float64, numba.float64)], target=\"cuda\")\n",
    "def func_numba_gpu(x, y):\n",
    "    return math.pow(x, 3.0) + 4 * math.sin(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69049a8-666e-4ca6-9fbc-7ac03f594e9a",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The commented-out variant `func_numpy` which uses numpy functions (`np.pow` and `np.sin`) would automatically vectorize and perform little better than the first two -  making it a better formulation for the purpose. \n",
    "**We don't do that here to illustrate vectorized functions which may be required for custom algorithms**.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc430e-1d26-4d78-840a-c3648ff84d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10000000\n",
    "mx = np.random.rand(N)\n",
    "result = np.empty_like(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c07e5c-6390-4734-a73e-5cb471b39e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -r 1 -q -o\n",
    "for i in range(N):\n",
    "    result[i] = func_cpu(mx[i], mx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9336e-19d3-4e3b-8233-1ccd47cc57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cpu = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb94dd-9f41-4a2b-bafc-4bcf0402f28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit -q -o result_numpy_cpu = func_numpy_cpu(mx, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c26d4-d386-443d-b5a2-3545109c0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_numpy_cpu = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d261a46-8853-4a42-a800-e1ecc4e3c972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit -q -o result_numba_cpu = func_numba_cpu(mx, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914f891-f524-4421-87b4-bed6bc0042b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_numba_cpu = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052449a-2dd1-412e-8eeb-69311100a0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit -q -o result = func_numba_gpu(mx, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c5c64-01ee-4bdb-80e3-25bf850c832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_numba_gpu = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d4821-6e55-43e6-815d-f662bf0dc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_timings(\n",
    "    cpu=time_cpu,\n",
    "    numpy_cpu=time_numpy_cpu,\n",
    "    numba_cpu=time_numba_cpu,\n",
    "    numba_gpu=time_numba_gpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f091c-abf7-4c3f-a6f5-6295cb7fd79e",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{note}\n",
    "- Using `ufunc` (or `gufunc`) for GPU programming may not always yield optimal performance due to automatic handling of data transfer and kernel launching.\n",
    "- In practical applications, not every function can be constructed as a `ufunc`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91dd946-84e1-4810-8ae6-1b56fba0d3fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 An example for vector addition with manual data transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64654d6f-0bdd-403c-a0d1-cc25f58366c9",
   "metadata": {},
   "source": [
    "Sometimes, for better performance, one need to calibrate kernels and manually manage data transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f771a27-ca6c-4f89-a58a-3dbea92e0015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "\n",
    "@numba.cuda.jit\n",
    "def func(a, b, c):\n",
    "    \"\"\"GPU vectorized addition. Computes C = A + B\"\"\"\n",
    "    # like threadIdx.x + (blockIdx.x * blockDim.x)\n",
    "    thread_id = numba.cuda.grid(ndim=1)\n",
    "    size = len(c)\n",
    "\n",
    "    if thread_id < size:\n",
    "        c[thread_id] = a[thread_id] + b[thread_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9330d069-94fc-4da0-870f-bc60f5619c78",
   "metadata": {},
   "source": [
    "Below, we explicitly move two arrays to the device memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf61f2-e62f-45be-a1f2-ca016833855e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10000000\n",
    "a = numba.cuda.to_device(np.random.random(N))\n",
    "b = numba.cuda.to_device(np.random.random(N))\n",
    "c = numba.cuda.device_array_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c06333-d2c8-41a7-b1d2-10a228dc0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4733df6-a6aa-4972-9ef4-69d604d3cfeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit -r 1 func.forall(len(a))(a, b, c)\n",
    "print(c.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c1cde-0d10-4643-bc60-0d4f66ad7d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nthreads = 256  # Enough threads per block for several warps per block\n",
    "nblocks = (len(a) // nthreads) + 1  # Enough blocks to cover entire vector\n",
    "\n",
    "%timeit -r 1 func[nblocks, nthreads](a, b, c)\n",
    "print(c.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b115e76-ad9a-4851-af4c-98b6e4a1a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "del a, b, c\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130bcc0d-4fb5-4420-b285-33b0d63804ce",
   "metadata": {},
   "source": [
    "## 3. Jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7052b6a-40f5-44ba-b352-ba3085f2e4e2",
   "metadata": {},
   "source": [
    ":::{important} `Jax` offers a drop-in import alias for Numpy and JIT compiler\n",
    "\n",
    "Although `Jax` was originally designed to build neural networks with built-in support for auto-differentiation, it\n",
    "can also be used to optimize other generic computation loads.\n",
    "\n",
    "- Like, CuPy (coming soon), using `import jax.numpy as jnp` provides access to a large subset of optimized Numpy functions.\n",
    "- Like Numba, we decorate with `@jax.jit` to JIT compile. Compiled function can run in GPU (CUDA and experimental ROCm support), TPU or CPU opportunistically.\n",
    "- Unlike Numba, Jax can only work with certain kinds of code: [pure functions, for-loops written differently, etc.](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html).\n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528e739-66de-4d20-8d48-69c629c43698",
   "metadata": {},
   "source": [
    "### 3.1 Jax as NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228b4c9-36e1-45a5-bb53-feb41df8074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((10, 10_000))\n",
    "data[5, 42] = np.nan\n",
    "data[7, 1111] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab7f3b-6a06-48fa-a7bd-a0b2f9e94a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute 90th percentile ignoring NaNs, and along the rows of an array\n",
    "time_numpy = %timeit -o np.nanpercentile(data, 90, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146c75f-3287-4330-9e8c-e96c0820017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "time_jax = %timeit -o -r 1 jnp.nanpercentile(data, 90, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598bbd5-7bdd-4e9c-8bb8-c21a333874b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_timings(numpy_percentile=time_numpy, jax_percentile=time_jax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f71c0-1cb3-4782-808a-333ed9a56331",
   "metadata": {},
   "source": [
    "### 3.2 Jax as JIT compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d105f-0785-4b65-96fe-9d41631a2e2e",
   "metadata": {},
   "source": [
    "Here we will revisit the example function shown in [section 2.2](#id-2-2-ufunc-and-gufunc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6c6ea-c926-495f-985f-49336b91842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "\n",
    "\n",
    "def func_numpy(x, y):\n",
    "    return np.power(x, 3.0) + 4 * np.sin(y)\n",
    "\n",
    "\n",
    "@jit\n",
    "def func_jax(x, y):\n",
    "    return jnp.power(x, 3.0) + 4 * jnp.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09693bfa-94de-438d-9c07-fd127850ed19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10000000\n",
    "mx = np.random.rand(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f93a0f-53f1-4354-bab0-26dfcd188ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_numpy = %timeit -o func_numpy(mx, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c62a71-535d-4b4b-b59d-fb7c04a9b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_jax = %timeit -o func_jax(mx, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33611d14-1896-4694-b9a7-4baa670e2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2c1ed-1aeb-41d9-913e-7f19a34f0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmx = jax.device_put(mx)\n",
    "\n",
    "time_jax_gpu = %timeit -o -n 50 func_jax(dmx, dmx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ccbfe-277f-46ca-9f4a-8731ca88d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_timings(numpy=time_numpy, jax=time_jax, jax_with_array_in_gpu=time_jax_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5b88d-a4fc-4043-a079-73a867c847a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mx, dmx\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ad36e6-843f-42e9-87cd-890eb6730c4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. CuPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e660cfaa-fda1-4487-a6c3-939d1c5be457",
   "metadata": {},
   "source": [
    ":::{important} `CuPy` is a NumPy/SciPy-compatible array library for GPU-accelerated computing with Python. \n",
    "- It has been developed for NVIDIA GPUs but has experimental support both NVIDIA and AMD GPUs.\n",
    "- All you need to do is replace `numpy` and `scipy` with `cupy` and `cupyx.scipy` in your Python code.\n",
    ":::\n",
    "\n",
    ":::{seealso}\n",
    "Tutorials:\n",
    "- https://docs.cupy.dev/en/stable/user_guide/basic.html\n",
    "- https://arc.leeds.ac.uk/lesson-gpu-programming/02-cupy/index.html\n",
    "- https://carpentries-incubator.github.io/lesson-gpu-programming/cupy.html\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108afec-2f54-4f51-9b1f-8617ad7ed86f",
   "metadata": {},
   "source": [
    "**Replacement of numpy with cupy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85512e3f-4b83-4e64-b9f3-b82816889381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "lst = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# creating arrays\n",
    "lst_cpu = np.array(lst)\n",
    "lst_gpu = cp.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6731f99-9ce9-4417-a9a9-fb8d18a39f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the Euclidean norm\n",
    "lst_cpu_norm = np.linalg.norm(lst_cpu)\n",
    "lst_gpu_norm = cp.linalg.norm(lst_gpu)\n",
    "\n",
    "print(\"Using Numpy: \", lst_cpu_norm)\n",
    "print(\"Using Cupy:  \", lst_gpu_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb1242b-67b3-40f6-88fa-6bec107dc39d",
   "metadata": {},
   "source": [
    "Same answer, same decimal precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796cdd7-19f3-4759-8025-4cfb6257a5c7",
   "metadata": {},
   "source": [
    "**Speed comparison between cupy and numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342348d-2a90-4e99-8c91-76dba81b6f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NumPy and CPU Runtime\n",
    "x_cpu = np.random.random((3000, 1000))\n",
    "time_numpy = %timeit -o -r 1 np.linalg.norm(x_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612c803-8000-40ed-94b6-3b53c4301e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CuPy and GPU Runtime\n",
    "x_gpu = cp.random.random((3000, 1000))\n",
    "time_cupy = %timeit -o -r 1 -n 10 cp.linalg.norm(x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9a839-ee3a-4161-9bc8-31bf6866a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_timings(norm_numpy=time_numpy, norm_cupy=time_cupy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76969a74-72bd-411e-9ceb-c369bfd7da6f",
   "metadata": {},
   "source": [
    "**Interfacing with user-defined Kernels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf5d28-c24d-429f-b7ef-63f01e3857a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x1 = cp.arange(25, dtype=cp.float32).reshape(5, 5)\n",
    "x2 = cp.arange(25, dtype=cp.float32).reshape(5, 5)\n",
    "\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7a34b-e550-4532-a884-714d6a43b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cp.zeros((5, 5), dtype=cp.float32)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ed02a-368c-47d2-99e5-ff81b344cae5",
   "metadata": {},
   "source": [
    "**Simpler approach**: we use `ElementwiseKernel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05e37b-e8af-4fde-82de-7f67ccbf9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_elemwise = cp.ElementwiseKernel(\n",
    "    \"float32 x1, float32 x2\", \"float32 y\", \"y = x1 + x2\", \"my_add_elemwise\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4271b97-47c4-457f-be0b-2675fae852af",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_elemwise(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd10db-ff47-474c-8a6b-99ef714baf97",
   "metadata": {},
   "source": [
    "**Complicated approach**: we use `RawKernel` which is essentially CUDA / C++ code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640996c-69ff-4c6c-a946-6c16f649a258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_kernel = cp.RawKernel(\n",
    "    r\"\"\"\n",
    "extern \"C\" __global__\n",
    "void my_add(const float* x1, const float* x2, float* y) {\n",
    "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    y[tid] = x1[tid] + x2[tid];\n",
    "}\n",
    "\"\"\",\n",
    "    \"my_add\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1573d50-74d6-4dba-9e2c-f49cfa1f2c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_kernel((5,), (5,), (x1, x2, y))  # grid, block and arguments\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073c3f0-048f-4e77-9e51-fdd017d4bce5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. PyCUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e87f6-02e3-461e-8a63-92098cb33671",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{important} [PyCUDA](https://pypi.org/project/pycuda/) is a Python programming environment for CUDA\n",
    "- It allows users to access to NVIDIA’s CUDA parallel computing API from Python.\n",
    "- PyCUDA is powerful library but only runs on NVIDIA GPUs.\n",
    "- Knowledge of CUDA programming is needed.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f986d-ba5e-4022-9136-2875a5098102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialization\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34591de-1678-4f17-81c1-6e45f0504637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Transferring data\n",
    "\n",
    "# 2.1: Generating numbers with single precision\n",
    "import numpy as np\n",
    "\n",
    "mx_cpu = np.random.randn(4, 4)\n",
    "mx_cpu = mx_cpu.astype(np.float32)\n",
    "print(mx_cpu, end=\"\\n\")\n",
    "\n",
    "# 2.2: Allocation of memory on GPU\n",
    "mx_gpu = cuda.mem_alloc(mx_cpu.nbytes)\n",
    "\n",
    "# 2.3: Transferring data from CPU (host) to GPU (device)\n",
    "cuda.memcpy_htod(mx_gpu, mx_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b741e9-f8a5-45f4-933b-54ac94e55069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Executing a kernel on GPU\n",
    "\n",
    "# 3.1 Definition of the kernel\n",
    "mod = SourceModule(\n",
    "    \"\"\"\n",
    "  __global__ void doublify(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] *= 2.0;\n",
    "  }\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "# 3.2 Compile this kernel, loading it onto GPU, and then call this kernel\n",
    "doublify = mod.get_function(\"doublify\")\n",
    "\n",
    "doublify(mx_gpu, block=(4, 4, 1), grid=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499403ed-3144-49b4-9d4f-2d32996aae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Transferring data from GPU (device) to CPU (host)\n",
    "\n",
    "mx_doubled = np.empty_like(mx_cpu)\n",
    "cuda.memcpy_dtoh(mx_doubled, mx_gpu)\n",
    "\n",
    "print(mx_cpu, \"\\n\\n\", mx_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7fa6f-18eb-42dd-8f38-5673ae8bc40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bonus: Abstracting Away the Complications\n",
    "# Using a pycuda.gpuarray to achieve the same effect with less writing\n",
    "\n",
    "import pycuda.gpuarray as gpuarray\n",
    "\n",
    "mx_gpu = gpuarray.to_gpu(np.random.randn(4, 4).astype(np.float32))\n",
    "mx_doubled = (2 * mx_gpu).get()\n",
    "\n",
    "print(mx_gpu, \"\\n\\n\", mx_doubled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
